{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "CREDIT_FILE_ID = '18P5oXUpch9s5Nm4WdV_fwjX4oBneyyuh'\n",
    "APPLICATION_FILE_ID = '1ET5jQSMcLj7odR1OttvR1qdcWtQ-CnaQ'\n",
    "BASE_DIR = '/Users/efrain.flores/Desktop/EF/EF/UnDosTres/data'\n",
    "GOT_TIME_TO_TRAIN = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entorno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Control de datos\n",
    "from pathlib import Path\n",
    "from requests import Session\n",
    "from pickle import dump as save_pkl, load as load_pkl\n",
    "\n",
    "# Ingeniería de variables\n",
    "from numpy import nan\n",
    "from pandas import DataFrame, read_csv, cut, qcut\n",
    "\n",
    "# Modelos\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Gráficas\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Código"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BussinessCase:\n",
    "    def __init__(self, base_dir: str=None) -> None:\n",
    "        '''\n",
    "        Sólo recibe el directorio de trabajo y la clase cuenta con los métodos suficientes para:\n",
    "            - limpieza\n",
    "            - entrenamiento\n",
    "            - predicción\n",
    "        '''\n",
    "        # Define el directorio como objeto Path para manejar eficientemente los archivos y directorios\n",
    "        if base_dir is not None: self.base_dir = Path(base_dir)\n",
    "        else: self.base_dir = Path().cwd()\n",
    "        self.main_dict = {}\n",
    "\n",
    "\n",
    "    def get_file(self, file_id: str, file_name: str) -> DataFrame:\n",
    "        '''\n",
    "        Extrae los archivos via Google Drive\n",
    "        '''\n",
    "        # Hace la solicitud a la URL y guarda la respuesta\n",
    "        session = Session()\n",
    "        URL = \"https://docs.google.com/uc?export=download\"\n",
    "        response = session.get(URL, params={'id':file_id, 'confirm':'t'}, stream=True)\n",
    "\n",
    "        # Guarda el archivo en el directorio descrito\n",
    "        file_dir = self.base_dir.joinpath(f'{file_name}.csv')\n",
    "        with open(file_dir, \"wb\") as f:\n",
    "            for chunk in response.iter_content(32768):\n",
    "                f.write(chunk)\n",
    "\n",
    "        df = read_csv(file_dir)\n",
    "        return df\n",
    "\n",
    "    \n",
    "    def get_both_files(self, credit_file: tuple, app_file: tuple) -> None:\n",
    "        self.credit = self.get_file(credit_file[0], credit_file[-1])\n",
    "        self.app = self.get_file(app_file[0], app_file[-1])\n",
    "        print(f'Los archivos:\\n\\t-{credit_file[-1]}.csv\\n\\t-{app_file[-1]}.csv\\nfueron importados exitosamente')\n",
    "\n",
    "\n",
    "    def mod_credit(self, id_col: str, status_col: str, date_col: str) -> DataFrame:\n",
    "        cred = self.credit.replace({\n",
    "            **{'C':'good', 'X':'good', '0':'good'},\n",
    "            **{str(x):'bad' for x in range(1,6)}\n",
    "        })\n",
    "        cred = cred.pivot_table(index=id_col, columns=date_col, values=status_col, aggfunc=lambda x:x)\n",
    "        cred.fillna('good', inplace=True)\n",
    "        return cred.astype(str)\n",
    "\n",
    "\n",
    "    def to_drop(self, df: DataFrame, col: str) -> None:\n",
    "        df.drop(col, axis=1, inplace=True)\n",
    "        return df\n",
    "\n",
    "\n",
    "    def to_range(self, df: DataFrame, col: str, is_train: bool, **kwargs) -> None:\n",
    "        # Función para convertir float: 1.0 --> str: '01'\n",
    "        def two_char(n): return str(int(n)).zfill(2)\n",
    "        # Encontrar el bin al cual el dato pertenece\n",
    "        if is_train:\n",
    "            df[col], self.main_dict['ranges'][col] = qcut(df[col], retbins=True, duplicates='drop', **kwargs)\n",
    "        else: \n",
    "            df[col] = cut(df[col], bins=self.main_dict['ranges'][col])\n",
    "        # Convertirlo a texto: [1.0 - 5.0] --> '01 a 05'\n",
    "        df[col] = df[col].map(lambda x: two_char(x.left+1)+' a '+two_char(x.right) if x!=nan else nan)\n",
    "        return df\n",
    "\n",
    "\n",
    "    def to_flag(self, df: DataFrame, col: str, option_list: list) -> None:\n",
    "        df[col] = df[col].map(lambda x: 0 if x in option_list else 1)\n",
    "        return df\n",
    "\n",
    "\n",
    "    def mod_app(self, id_col: str, to_drop_cols: list, to_range_cols: list, to_flag_cols: list, **kwargs) -> None:\n",
    "        X = self.app.drop_duplicates(id_col)\n",
    "        X = X[X[id_col].isin(self.credit[id_col])].copy()\n",
    "        X.set_index(id_col, inplace=True)\n",
    "\n",
    "        bc.main_dict['ranges'] = {}\n",
    "        for col in to_drop_cols: X = self.to_drop(X, col)\n",
    "        for col in to_range_cols: X = self.to_range(X, col, **kwargs)\n",
    "        for col, opt in to_flag_cols: X = self.to_flag(X, col, opt)\n",
    "        return X.astype(str)\n",
    "\n",
    "\n",
    "    def cm_sklearn(self, X: DataFrame, y: DataFrame, fit_model, target_encoder) -> DataFrame:\n",
    "        '''\n",
    "        Muestra la matriz de confusión en un mapa de calor\n",
    "        '''\n",
    "        # Regresa los números a etiquetas originales\n",
    "        labels = target_encoder.inverse_transform(fit_model.classes_)\n",
    "        # Calcula la matriz de confusión, real vs estimado\n",
    "        cm = DataFrame(confusion_matrix(y_true=y.values, y_pred=fit_model.predict(X)), index=labels, columns=labels).replace({0:nan})\n",
    "        \n",
    "        # Define el tamaño de el mapa de calor\n",
    "        size = len(cm)//2\n",
    "        fig, ax = plt.subplots(figsize=(size, size)) \n",
    "        # Crea el mapa de calor con base en la distribución % del valor real a través de sus predicciones\n",
    "        to_heatmap = DataFrame([cm[col] / cm.sum(axis=1) for col in cm.columns], index=labels, columns=labels).T\n",
    "        sns.heatmap(to_heatmap, annot=True, fmt='.0%',cmap='Blues', linewidths=0.5, ax=ax, cbar=False)\n",
    "        plt.show()\n",
    "        return cm\n",
    "\n",
    "    \n",
    "    def save_model(self, model, model_name: str) -> None:\n",
    "        '''\n",
    "        Exporta el modelo en modo diccionario para que cuando se importe, se conozca de qué trata el objeto\n",
    "        '''\n",
    "        self.models_dir = self.base_dir.joinpath('model')\n",
    "        self.models_dir.mkdir(exist_ok=True)\n",
    "\n",
    "        self.main_dict[model_name] = model\n",
    "\n",
    "        with open(self.models_dir.joinpath(f'{model_name}.xz'), 'wb') as f:\n",
    "            # Como diccionario para conocer su nombre\n",
    "            save_pkl(self.main_dict, f)\n",
    "\n",
    "        print(f'El modelo {model_name}.xz ha sido guardado exitosamente en:\\n{self.models_dir}')\n",
    "\n",
    "\n",
    "    def get_model(self, model_name: str) -> None:\n",
    "        with open(self.models_dir.joinpath(f'{model_name}.xz'), 'rb') as f:\n",
    "            # Como diccionario para conocer su nombre\n",
    "            model_dict = load_pkl(f)\n",
    "            \n",
    "        # Confirma que el archivo fue guardado exitosamente\n",
    "        print(f'El modelo {model_name}.xz fue importado existosamente desde:\\n{self.models_dir}')\n",
    "        return model_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bc = BussinessCase(BASE_DIR)\n",
    "bc.get_both_files((CREDIT_FILE_ID, 'credit'), (APPLICATION_FILE_ID, 'app'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clientes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pre = bc.mod_app(\n",
    "    id_col='ID',\n",
    "    is_train=True,\n",
    "    to_drop_cols=['FLAG_MOBIL'],\n",
    "    to_range_cols=['AMT_INCOME_TOTAL','DAYS_BIRTH','DAYS_EMPLOYED','CNT_FAM_MEMBERS'], q=10,\n",
    "    to_flag_cols=[\n",
    "        ('CNT_CHILDREN',['0']),\n",
    "        ('NAME_HOUSING_TYPE',['House / apartment']),\n",
    "        ('OCCUPATION_TYPE', [nan])\n",
    "    ]\n",
    ")\n",
    "\n",
    "X_pre.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Historia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pre = bc.mod_credit(id_col='ID', status_col='STATUS', date_col='MONTHS_BALANCE')\n",
    "y_pre.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## f(X) = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = X_pre.join(y_pre)\n",
    "X = df.loc[:, :-1].copy()\n",
    "X.columns = list(map(str, X.columns))\n",
    "y = df[[0]].copy()\n",
    "\n",
    "X.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conjunto validación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "\n",
    "skf = StratifiedKFold(n_splits=4, shuffle=False)\n",
    "\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "\n",
    "y_encod = LabelEncoder()\n",
    "y_train = DataFrame(y_encod.fit_transform(y_train), index=y_train.index)\n",
    "y_test = DataFrame(y_encod.transform(y_test), index=y_test.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hiperparametrización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "if GOT_TIME_TO_TRAIN:\n",
    "    from sklearn.metrics import make_scorer, matthews_corrcoef\n",
    "    from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "    param_logreg = {\n",
    "        'penalty':['l1', 'l2'], \n",
    "        'C':[x + y/10 for x in range(5) for y in range(1,5)], \n",
    "        'class_weight':['balanced'],\n",
    "        'solver':['liblinear'],\n",
    "        # 'solver':['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "    }\n",
    "    search_logreg = RandomizedSearchCV(\n",
    "        estimator=LogisticRegression(max_iter=100),\n",
    "        param_distributions=param_logreg,\n",
    "        scoring=make_scorer(matthews_corrcoef),\n",
    "        n_iter=4,\n",
    "        verbose=1,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "else: search_logreg = LogisticRegression(max_iter=5000, class_weight='balanced', solver='liblinear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from category_encoders.cat_boost import CatBoostEncoder\n",
    "\n",
    "models = {}\n",
    "models['model'] = {}\n",
    "models['scores'] = {}\n",
    "for i, indexes in enumerate(skf.split(X_train, y_train)):\n",
    "    train, test = indexes\n",
    "    models['model'][i] = make_pipeline(CatBoostEncoder(), SMOTE(sampling_strategy='minority'), search_logreg)\n",
    "    models['model'][i].fit(X_train.iloc[train,:], y_train.iloc[train,:].values)\n",
    "    prediction = models['model'][i].predict(X_train.iloc[test,:])\n",
    "    models['scores'][i] = matthews_corrcoef(y_train.iloc[test,:], prediction)\n",
    "\n",
    "models = DataFrame(models).sort_values('scores', ascending=False)\n",
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.iloc[0,0]\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = bc.cm_sklearn(X_test, y_test, model, y_encod)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exportar modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bc.save_model({'model':model, 'encod':y_encod}, model_name='BussinessCase')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importar modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ready_to_use = bc.get_model(model_name='BussinessCase')\n",
    "ready_to_use['BussinessCase']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resumen (por trabajar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "47 ID duplicados con diferentes datos (apenas el 0.01%)\n",
    "Sólo hay historia de 45985 clientes\n",
    "Existen 9528 ID con historia pero no están registrados\n",
    "Clientes registrados y con historia -> 36457 (8.3% de los usuarios únicos registrados)\n",
    "\n",
    "CODE_GENDER -> cool\n",
    "FLAG_OWN_CAR -> cool\n",
    "FLAG_OWN_REALTY -> cool\n",
    "NAME_INCOME_TYPE -> cool\n",
    "NAME_EDUCATION_TYPE -> cool\n",
    "NAME_FAMILY_STATUS -> cool\n",
    "\n",
    "FLAG_WORK_PHONE -> CAT\n",
    "FLAG_PHONE -> CAT\n",
    "FLAG_EMAIL -> CAT\n",
    "\n",
    "FLAG_MOBIL -> borrar porque todo es 1\n",
    "\n",
    "AMT_INCOME_TOTAL -> CAT rangos\n",
    "DAYS_BIRTH -> CAT rangos\n",
    "DAYS_EMPLOYED -> CAT rangos\n",
    "CNT_FAM_MEMBERS -> CAT rangos\n",
    "\n",
    "CNT_CHILDREN -> CAT flag 0 o >0\n",
    "NAME_HOUSING_TYPE -> CAT flag house?\n",
    "OCCUPATION_TYPE -> CAT is null?\n",
    "\n",
    "Clasificación o regresión?\n",
    "0 -> 1 ?\n",
    "X, C -> -1 ?\n",
    "'mean' o 'sum'?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7115035df2ff0c7e4fcaf42295c9545e991133b7698ec02afe41cbdbfc589532"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
